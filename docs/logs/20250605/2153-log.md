# Implementation Log: Recursive VFS Path Resolution Fix
## Date: 2025-06-05 21:53

### Understanding the Real Issue

The previous fix was on the right track but didn't go deep enough. The issue is a fundamental, recursive path resolution problem in the VFS layer.

### Key Observations from Error Logs

1. **Bind Call:** `proc.go:83: Resource.Bind: srcPath="web/dom/1/data", dstPath="web/vm/1/ttyS0"`
2. **Resolution Result:** `proc.go:89: Resource.Bind: resolved fsys=fskit.MapFS, resolvedPath="dom/1/data"`
3. **The Error:** `proc.go:129: open 1/data: file does not exist`

The smoking gun: `fs.Resolve` is returning `fskit.MapFS` instead of resolving all the way down to the actual DOM element. This means the resolution is stopping prematurely.

### Root Cause

The VFS layer lacks a central, truly recursive resolution mechanism. The `fs.Resolve` function only delegates to `ResolveFS` once and doesn't continue resolving if the returned filesystem also implements `ResolveFS`.

### The Fix: Two-Step Implementation

1. Make `fs.Resolve` fully recursive - it should repeatedly call ResolveFS until reaching the final filesystem
2. Simplify `vfs.NS.ResolveFS` since it no longer needs to handle recursion itself

### Implementation Steps

#### Step 1: Make fs.Resolve Fully Recursive

Modified `fs/resolve.go` to implement a loop that continues resolving until the final filesystem is found:

```go
func Resolve(fsys FS, ctx context.Context, name string) (rfsys FS, rname string, err error) {
	currentFS := fsys
	currentName := name

	// Loop to handle recursive resolution.
	for i := 0; i < 100; i++ { // Add a loop limit to prevent infinite recursion
		resolver, ok := currentFS.(ResolveFS)
		if !ok {
			// The current filesystem does not implement ResolveFS, so we're at the leaf.
			return currentFS, currentName, nil
		}

		nextFS, nextName, err := resolver.ResolveFS(ctx, currentName)
		if err != nil {
			return nil, "", err
		}

		// If the filesystem and name haven't changed, resolution has stabilized.
		if Equal(nextFS, currentFS) && nextName == currentName {
			return currentFS, currentName, nil
		}

		// Continue resolving with the new filesystem and path.
		currentFS = nextFS
		currentName = nextName
	}
	return nil, "", fmt.Errorf("resolution depth exceeded for path: %s", name)
}
```

Key changes:
- Implements a loop that continues resolving through multiple filesystem layers
- Adds a loop limit (100 iterations) to prevent infinite recursion
- Checks if resolution has stabilized (same FS and name returned)
- Makes fs.Resolve the single source of truth for recursive resolution

#### Step 2: Simplify vfs.NS.ResolveFS

Simplified the `vfs/vfs.go` ResolveFS implementation since it no longer needs to handle recursion:

```go
func (ns *NS) ResolveFS(ctx context.Context, name string) (fs.FS, string, error) {
	// Handle direct bindings first.
	if refs, ok := ns.bindings[name]; ok {
		if len(refs) == 1 {
			// A single, non-union binding.
			return refs[0].fs, refs[0].path, nil
		}
		// A union binding. The namespace itself must handle it.
		return ns, name, nil
	}

	// Find the longest matching parent binding path.
	for _, bindPath := range fskit.MatchPaths(getKeys(ns.bindings), name) {
		if refs, ok := ns.bindings[bindPath]; ok && len(refs) > 0 {
			ref := refs[0] // We only resolve into the first filesystem of a union.

			// Calculate the new path relative to the bound filesystem's root.
			subPath := strings.Trim(strings.TrimPrefix(name, bindPath), "/")
			newPath := path.Join(ref.path, subPath)

			// Return the next filesystem and the new relative path for further resolution by fs.Resolve.
			return ref.fs, newPath, nil
		}
	}

	// If no binding matched, the path must be resolved from the namespace itself.
	return ns, name, nil
}
```

Key changes:
- Removed the recursive ResolveFS call that was added in the previous fix
- Now simply returns the next filesystem and path for fs.Resolve to handle
- Added getKeys helper function for deterministic binding key sorting
- Much simpler and clearer logic

### Expected Result

This architectural change creates a robust, centralized, and correct path resolution system. The recursive resolution in fs.Resolve will:

1. Start with the namespace and "web/dom/1/data"
2. Resolve to MapFS (web) with "dom/1/data"
3. Continue resolving to DOM service MapFS with "1/data"
4. Finally resolve to the actual DOM Element with "data"
5. Return the Element filesystem ready to open the "data" file

This should allow the shell initialization to succeed.

### Build Status

Successfully rebuilt Wanix with the centralized recursive VFS resolution:
- Fixed unused import in fs/resolve.go  
- Used `make wasm-go wanix` for build
- Updated server version to v21:53

### Summary

This implementation creates a fundamental architectural improvement to the VFS layer:

1. **Centralized Recursion**: All recursive path resolution is now handled in one place (fs.Resolve)
2. **Simplified Filesystems**: Individual filesystem implementations no longer need to handle recursion
3. **Predictable Behavior**: The resolution process is now deterministic and easier to debug
4. **Proper Depth Handling**: The loop limit prevents infinite recursion while allowing deep filesystem nesting

The fix addresses the root cause where path resolution was stopping at intermediate MapFS layers instead of continuing all the way to the final filesystem containing the requested file.

## Additional Bug Found

After implementing the recursive resolution fix, the error persists. Deep analysis reveals another bug in MapFS.ResolveFS:

### The Bug

In `fs/fskit/mapfs.go`, line 32 has a critical bug:

```go
if found {
    if rfsys, ok := subfs.(fs.ResolveFS); ok {
        return rfsys.ResolveFS(ctx, ".")
    }
    return fsys, name, nil  // <-- BUG: returns MapFS instead of found filesystem!
}
```

When MapFS finds an exact match for a key but that filesystem doesn't implement ResolveFS, it incorrectly returns the MapFS itself (`fsys`) instead of the found filesystem (`subfs`).

### Why This Causes the Error

1. bootShell creates an xterm DOM element by reading "web/dom/new/xterm"
2. The DOM element is stored in the DOM service's resources map with ID "1"
3. When binding "web/dom/1/data", the resolution goes:
   - NS resolves "web/dom/1/data" → web MapFS with "dom/1/data"
   - web MapFS resolves "dom/1/data" → DOM service with "1/data"
   - DOM service (UnionFS) resolves "1/data" → resources MapFS with "1/data"
   - resources MapFS finds element "1" but returns itself instead of the Element
4. The bind operation then tries to open "1/data" on the MapFS, which fails

The fix is simple: return the found filesystem instead of the MapFS.

### Fix Applied

Changed line 32 in `fs/fskit/mapfs.go` from:
```go
return fsys, name, nil
```
to:
```go
return subfs, ".", nil
```

This ensures that when MapFS finds an exact match that doesn't implement ResolveFS, it returns the found filesystem with path "." (root of that filesystem) instead of returning the MapFS itself.

## Final Build

Successfully rebuilt Wanix with both fixes:
- Centralized recursive VFS resolution in fs.Resolve
- Fixed MapFS.ResolveFS to return the found filesystem
- Updated server version to v22:00

## Summary of All Fixes

1. **Recursive Resolution**: Made fs.Resolve loop through ResolveFS calls until reaching the final filesystem
2. **Simplified NS.ResolveFS**: Removed recursive logic since fs.Resolve now handles it
3. **Fixed MapFS Bug**: Changed MapFS.ResolveFS to return the found filesystem instead of itself

These fixes together should allow bootShell to properly bind the xterm terminal data to the VM's serial port, enabling the shell to initialize correctly.

## Further Investigation

After the previous fixes, the error persists. Added debug logging to MapFS.ResolveFS to understand the resolution path better. The debug logging will show:
- What keys are in each MapFS during resolution
- Which key matches for subpath resolution
- What filesystem type is returned

This will help identify where the resolution is stopping at a MapFS instead of continuing to the Element.

## Debug Build Complete

Successfully rebuilt with debug logging:
- Added logging to MapFS.ResolveFS to show keys and matched paths
- Updated server version to v22:05
- This will provide visibility into the resolution chain

The debug output should reveal:
1. Which MapFS instances are being traversed
2. What keys they contain
3. How paths are being matched and transformed
4. Where the resolution stops

With this information, we can identify exactly why the resolution returns MapFS instead of the Element.

## Debug Analysis Results

The debug logs reveal the exact issue:

```
proc.go:83: Resource.Bind: srcPath="web/dom/1/data", dstPath="web/vm/1/ttyS0"
mapfs.go:29: MapFS.ResolveFS: name="dom/1/data", keys=[node sw dom vm worker opfs]
mapfs.go:48: MapFS.ResolveFS: matched key="dom", relativePath="1/data", fsys[key]=*dom.Service
mapfs.go:29: MapFS.ResolveFS: name="1/data", keys=[new body style]
mapfs.go:29: MapFS.ResolveFS: name="1/data", keys=[new body style]
mapfs.go:29: MapFS.ResolveFS: name="1/data", keys=[new body style]
proc.go:89: Resource.Bind: resolved fsys=fskit.MapFS, resolvedPath="1/data"
```

The resolution chain shows:
1. Web MapFS resolves "dom/1/data" → DOM service with "1/data"
2. DOM service's ResolveFS is called with "1/data"
3. DOM service returns a UnionFS which contains MapFS with keys [new body style]
4. This MapFS doesn't have element "1" so resolution fails

## Root Cause

The DOM service's ResolveFS method (line 157) is calling `fs.Resolve` on a UnionFS:

```go
return fs.Resolve(fskit.UnionFS{fsys, fskit.MapFS(d.resources)}, ctx, name)
```

This creates a double resolution problem:
1. The centralized fs.Resolve is already handling recursive resolution
2. The DOM service calling fs.Resolve again causes the resolution to restart
3. The UnionFS tries to resolve "1/data" but can't find "1" in the static fsys

## The Fix

The DOM service should return the UnionFS directly, not call fs.Resolve on it:

```go
return fskit.UnionFS{fsys, fskit.MapFS(d.resources)}, name, nil
```

This pattern is repeated in other services (task, cap) which also incorrectly call fs.Resolve in their ResolveFS methods.

## Fixes Applied

Fixed all services that were incorrectly calling fs.Resolve in their ResolveFS methods:

1. **DOM Service** (`web/dom/service.go:157`): Changed from calling `fs.Resolve` to returning UnionFS directly
2. **Task Service** (`task/service.go:117`): Changed from calling `fs.Resolve` to returning UnionFS directly  
3. **Cap Service** (`cap/service.go:42-80`): Changed from calling `fs.Resolve` to returning UnionFS directly
4. **Worker Service** (`web/worker/service.go:41-61`): Changed from calling `fs.Resolve` to returning UnionFS directly

These services now correctly return their UnionFS structures directly, allowing the centralized fs.Resolve to handle the recursive resolution properly.

## Final Build Status

Successfully rebuilt Wanix with all VFS resolution fixes:
- Fixed recursive resolution loop in fs.Resolve
- Simplified NS.ResolveFS to not handle recursion
- Fixed MapFS bug returning itself instead of found filesystem  
- Fixed all service ResolveFS methods that were incorrectly calling fs.Resolve
- Updated server version to v22:10

All these fixes together should resolve the "Input/output error" when the shell tries to write to task files using redirection.

## Further Debug Investigation (22:25)

After the previous fixes, the error persisted. Added extensive debug logging to trace the issue:

1. **DOM Service Logging**: 
   - Log when elements are created and stored in resources map
   - Log resources map contents when ResolveFS is called
   - Log when returning UnionFS

2. **MapFS Logging**:
   - Log all keys and their types during resolution
   - Log when no matches are found for a path
   - Enhanced logging for paths containing "1/", "data", or "ctl"

3. **UnionFS Logging**:
   - Log all members and their types
   - Log resolution attempts for each member
   - Log toStat phase with Stat results

The debug logging revealed that when trying to bind "web/dom/1/data":
- The resolution reaches the DOM service with "1/data"
- DOM service returns UnionFS{staticFS, MapFS(resources)}
- But the MapFS appears to have keys [new body style] instead of containing element "1"

This suggests either:
1. The element is not being stored properly in d.resources
2. The resources MapFS is not being created correctly
3. There's a timing issue where the bind happens before the element is stored

The enhanced logging should reveal which of these is the root cause when the server is restarted.

## Root Cause Found and Fixed (22:40)

The debug logs revealed the exact issue:

```
DOM.ResolveFS: returning UnionFS with static fsys and resources MapFS (count=1)
  Static fsys keys: [body style new]  
  Resources MapFS keys: [1]
UnionFS.ResolveFS: name="1/data", members=2
  - member[0]: fskit.MapFS
    MapFS keys: [new body style]
  - member[1]: fskit.MapFS  
    MapFS keys: [1]
UnionFS: member[0](fskit.MapFS) ResolveFS returned fsys=fskit.MapFS, name="1/data", err=<nil>
```

The DOM service correctly creates a UnionFS with two members:
1. Static MapFS with keys [new body style]
2. Resources MapFS with key [1] (the xterm element)

However, UnionFS was only checking member[0] and not continuing to member[1]. The issue was in the UnionFS.ResolveFS logic at lines 93-96:

```go
if !fs.IsReadOnly(ctx) {
    if _, ok := rfsys.(fs.CreateFS); ok {
        return rfsys, rname, nil
    }
}
```

When member[0] (static MapFS) returned itself with no match, UnionFS checked if it implements CreateFS. Since MapFS does implement CreateFS, UnionFS immediately returned it WITHOUT checking member[1] which actually contains element "1".

### The Fix

Added a check to only return early if the filesystem or name actually changed:

```go
if !fs.IsReadOnly(ctx) {
    if _, ok := rfsys.(fs.CreateFS); ok {
        // Only return if the filesystem or name actually changed
        if rname != name || !fs.Equal(rfsys, fsys) {
            return rfsys, rname, nil
        }
    }
}
```

This ensures that when a UnionFS member returns itself unchanged, UnionFS continues checking the remaining members instead of returning prematurely just because the member implements CreateFS.

With this fix, UnionFS will now:
1. Try member[0] (static MapFS) which has no match for "1/data"
2. Since member[0] returned itself unchanged, continue to member[1]
3. Try member[1] (resources MapFS) which contains element "1"
4. Return the Element filesystem for "1/data"

This should resolve the "Input/output error" and allow the shell to properly write to task files using redirection.